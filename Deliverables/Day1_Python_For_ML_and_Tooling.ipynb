{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20cd986e-fe47-48ca-891e-2a3978540a2b",
      "metadata": {},
      "source": [
        "# ***Python for ML***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "294ab0f9-997a-4ee9-8ec3-d8011c85537a",
      "metadata": {},
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7d3628a-dea9-4820-9aa6-e8e0340d6572",
      "metadata": {},
      "source": [
        "##### This is day 1 of my **2-weeks AI/ML Engineer Learning plan**. Today, the libraries such as *NumPY* and *Pandas* which handles array and data manipulation were explored and discussed. Also, different libraries were also discussed such as *Matplotlib* and *Seaborn* for displaying pl. Furthermore, I have used the following datasets for exploring different types of syntax for Pandas:  \n",
        "\n",
        "##### - Pokemon dataset\n",
        "##### - Titanic dataset from Kaggle\n",
        "\n",
        "##### Agenda\n",
        "\n",
        "##### - Comfortably manipulate arrays with NumPy\n",
        "##### - Perform real data manipulation using Pandas\n",
        "##### - Conduct basic Exploratory Data Analysis (EDA)\n",
        "##### - Produce a clean, professional Jupyter Notebook"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dc367063-5eff-4196-b5b0-eebe21c67aba",
      "metadata": {},
      "source": [
        "## Data Loading\n",
        "\n",
        "##### In this section, NumPy library is used to manipulate, create and edit arrays. Moreover, the objectives of this section is to:\n",
        "\n",
        "##### - Understand NumPy arrays vs Python lists\n",
        "##### - Perform vectorized operations\n",
        "##### - Learn broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ca24c0-8fc2-4360-8241-acdc5bb1564b",
      "metadata": {},
      "source": [
        "#### Step 1: Add *NumPy* to Python Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d82f02d-c7e1-4255-b5b8-6a05ea91e60f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c40c2a2-a4c7-4b24-8fad-e1508fa3af77",
      "metadata": {},
      "source": [
        "#### Step 2: Load *NumPy* in the notebook by importing numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "258c7170-5353-4ab6-9c0e-052534db0e5f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd1d95c-b00a-4094-a3f9-baba3209eaeb",
      "metadata": {},
      "source": [
        "#### Step 3: Do Hands-on Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc0afd2-76b7-4615-aa0b-5940edcddb30",
      "metadata": {},
      "source": [
        "##### Create 1D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d5bdf504-7b28-42e1-8cba-2dff26f6cc57",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([1, 2, 3])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9254b19b-ad7d-4cfe-9853-a68af0eaf19a",
      "metadata": {},
      "source": [
        "##### Create 2D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fe8d1a2a-aecf-4c7a-b46a-a0c6946bbcc3",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ],
      "source": [
        "b = np.array([[1, 2, 3],[4, 5, 6]])\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a52951-5a73-4227-95af-b332f5ff4fb8",
      "metadata": {},
      "source": [
        "##### Perform matrix addition and multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cb838fbb-36b6-4c87-b506-523813f44011",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 4 6]\n",
            " [5 7 9]]\n"
          ]
        }
      ],
      "source": [
        "c = a+b\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b599ec98-d845-421a-ab4e-44894e8833ac",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1  4  9]\n",
            " [ 4 10 18]]\n"
          ]
        }
      ],
      "source": [
        "c = a*b\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7958d06c-0d55-43f9-8c4a-86e07100679d",
      "metadata": {},
      "source": [
        "##### Apply broadcasting manually and verify results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5eeaa8a5-1ea4-4953-ad04-cf7dc0d382f8",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original a:\n",
            " [1 2 3]\n",
            "Original b:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "Manually broadcasted a:\n",
            " [[1 2 3]\n",
            " [1 2 3]]\n",
            "Manual calculation (b + a_stretched):\n",
            " [[2 4 6]\n",
            " [5 7 9]]\n"
          ]
        }
      ],
      "source": [
        "# Manually expand y's dimension using np.newaxis or None\n",
        "a_broadcasted = a[np.newaxis, :] # Shape is now (1, 3)\n",
        "\n",
        "# Manually create the full array by tiling (replicating) the values\n",
        "a_stretched = np.tile(a_broadcasted, (2, 1)) # Shape is now (2, 3)\n",
        "\n",
        "# Perform element-wise addition on the stretched arrays\n",
        "manual_result = b + a_stretched\n",
        "\n",
        "print(\"Original a:\\n\", a)\n",
        "print(\"Original b:\\n\", b)\n",
        "print(\"Manually broadcasted a:\\n\", a_stretched)\n",
        "print(\"Manual calculation (b + a_stretched):\\n\", manual_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc9cabbd-b6e8-4fb0-8534-3edd02ee9d76",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "##### In this section, *Pandas* is used for data manipulation of the dataset \"Pokemon\" which came from the youtube tutorial entitled \"Pandas tutorial - Corey Schafer\".\n",
        "\n",
        "##### Agenda\n",
        "\n",
        "##### - Load datasets\n",
        "##### - Clean and transform data\n",
        "##### - Prepare data for ML pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2beae72f-a698-4874-b431-ce2a95da1e0c",
      "metadata": {},
      "source": [
        "#### Step 1: Add *Pandas* library in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf994336-b02b-473e-a755-4243dc44fe07",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "700dd461-2ae4-4336-8efd-e382cc5214e8",
      "metadata": {},
      "source": [
        "#### Step 2: Load *Pandas* in the notebook by importing pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd3e1ee8-68c3-45d9-a1d1-9bcf45727696",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84fcfdca-a3cd-42c5-b936-46a355a99431",
      "metadata": {},
      "source": [
        "#### Step 3: Do Hands-on Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96af6427-3ded-491f-895e-6ae602708a82",
      "metadata": {},
      "source": [
        "##### Load CSV dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c43fa8-d373-4938-826e-1684c6c032e9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"pokemon.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d28c763-be9a-4a13-a3d5-4f5413159478",
      "metadata": {},
      "source": [
        "##### Filter rows based on conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00be0840-97c2-48ee-a0d4-cc212e82afc4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Filter all items which are grass and poison type pokemons with HP greater than 70\n",
        "new_df = df.loc[(df['Type 1'] == 'Grass') & (df['Type 2'] == 'Poison') & (df['HP'] > 70)]\n",
        "\n",
        "new_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "new_df.to_csv('filtered.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f3713c2-2623-47f5-b32e-256772d28324",
      "metadata": {},
      "source": [
        "##### Fill or drop missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b9be460a-3ce0-4d84-8eb6-cd20937d2603",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTotal\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m.iloc[:, \u001b[32m4\u001b[39m:\u001b[32m10\u001b[39m].sum(axis=\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m cols = \u001b[38;5;28mlist\u001b[39m(df.columns)\n\u001b[32m      4\u001b[39m df = df[cols[\u001b[32m0\u001b[39m:\u001b[32m4\u001b[39m] + [cols[-\u001b[32m1\u001b[39m]] + cols[\u001b[32m4\u001b[39m:\u001b[32m12\u001b[39m]]\n",
            "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# Drop \"Total\" column in the table\n",
        "df['Total'] = df['HP'] + df['Attack'] + df['Defense'] + df['Sp. Atk'] + df['Sp. Def'] + df['Speed']\n",
        "\n",
        "df = df.drop(columns=['Total'])\n",
        "\n",
        "# Add \"Total\" column in the table between \"Type 2\" and \"HP\" columns\n",
        "df['Total'] = df.iloc[:, 4:10].sum(axis=1)\n",
        "\n",
        "cols = list(df.columns)\n",
        "df = df[cols[0:4] + [cols[-1]] + cols[4:12]]\n",
        "\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d3d0643-485f-48bc-9cd5-9d2ccb36826f",
      "metadata": {},
      "source": [
        "##### Compute summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "394a45a0-719b-4bb2-8b4d-19df5c4a0e88",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Aggregate statistics using groupby() method\n",
        "df = pd.read_csv('modified.csv')\n",
        "\n",
        "df['count'] = 1\n",
        "\n",
        "df.groupby(['Type 1', 'Type 2']).count()['count']\n",
        "\n",
        "#Compute summary statistics using describe() method\n",
        "\n",
        "summary = df.describe(include'all')\n",
        "\n",
        "print(\"\\nAll Columns Summary:\")\n",
        "print(summary_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa030338-3142-4b1a-91f3-3d1306b4eeeb",
      "metadata": {},
      "source": [
        "## EDA (Exploratory Data Analysis)\n",
        "\n",
        "##### This section covers Exploratory Data Analysis which uses statistics and visualizations to further understand dataset's features, discover anomalies and correlations between values and uncover patterns.\n",
        "\n",
        "##### Agenda\n",
        "\n",
        "##### - Understand dataset structure\n",
        "##### - Identify patterns, outliers and distributions\n",
        "##### - Build intuition before modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e246d0ed-5a2a-4e6f-99cc-e4c92580b589",
      "metadata": {},
      "source": [
        "#### Hands-on Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd487109-aaf4-4379-b14a-dd758fef8395",
      "metadata": {},
      "source": [
        "##### Analyze numerical vs categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5650bf8f-8c52-4c5d-9255-6ff74a8d2b8b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Load train.csv in Kaggle Titanic dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "#Data Manipulation\n",
        "df = df[['PassengerId', 'Survived', 'Pclass', 'Age', 'Parch','Fare', 'Embarked']].copy()\n",
        "df= df.rename(columns={'PassengerId': 'ID'})\n",
        "print(df['Fare'].value_counts()).head(5).plot()\n",
        "\n",
        "#Determine the categories and their types\n",
        "df.columns\n",
        "df.dtypes()\n",
        "\n",
        "#Show numerical features\n",
        "df.describe() \n",
        "\n",
        "#Show categorical columns\n",
        "df.describe(include=['O', 'category']) \n",
        "\n",
        "# General descriptive statistics for all numerical columns\n",
        "print(df.select_dtypes(include=['number']).describe())\n",
        "\n",
        "# Plotting a histogram for a specific numerical column\n",
        "df['numerical_column'].hist()\n",
        "plt.title('Distribution of Numerical Column')\n",
        "plt.show()\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation_matrix = df.select_dtypes(include=['number']).corr()\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Heatmap of Numerical Feature Correlations')\n",
        "plt.show()\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation_matrix = df.select_dtypes(include=['number']).corr()\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Heatmap of Numerical Feature Correlations')\n",
        "plt.show()\n",
        "\n",
        "# Plotting a bar chart for a specific categorical column's value counts\n",
        "df['categorical_column'].value_counts().plot(kind='bar')\n",
        "plt.title('Count of Categories')\n",
        "plt.show()\n",
        "\n",
        "# Calculate mean of a numerical column grouped by a categorical column\n",
        "print(df.groupby('categorical_column')['numerical_column'].mean())\n",
        "\n",
        "# Get a more comprehensive statistical summary using .describe() after grouping\n",
        "print(df.groupby('categorical_column')['numerical_column'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4d30fd-4cf0-4ee0-a61d-f35ef3d9c1ed",
      "metadata": {},
      "source": [
        "##### Identify potential target leakage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a466da4-2c83-4073-b888-5ef0abbf3fed",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "corr_matrix = df.corr(numeric_only=True)\n",
        "\n",
        "# Visualize the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Example: Grouped analysis for a categorical feature 'Feature_A'\n",
        "print(df.groupby('Feature_A')['target'].mean())\n",
        "\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
        "profile.to_file(\"Report.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3554b714-3de1-4f6a-ada6-2915cf76e492",
      "metadata": {},
      "source": [
        "##### Write insights in markdown cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f60721-fdca-4bbc-87fe-f1c34dade1a3",
      "metadata": {},
      "source": [
        "##### - Gender heavily correlates to the survival category of the dataset.\n",
        "##### - Age was also significant because the number of persons with younger age has the higher probabilities for survival compared to those with older age.\n",
        "##### - Family Size which is determined by \"SibSp and Parch\" also correlates to the survival. Small family size had the highest survival rates."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6aba274-8544-4992-9b2a-4a96b3c1b769",
      "metadata": {},
      "source": [
        "## Key Observations\n",
        "\n",
        "#### - Array Manipulation using *NumPy* is much more useful compared to using lists in Python because of the following factors:\n",
        "\n",
        "####        - *NumPy* uses contiguous memory compared to lists. This means that the data in Numpy is stored adjacently, which improves efficient caching and memory optimization.\n",
        "####        - *NumPy* also consumes less memory compared to lists. *NumPy* is stored as float or int (usually 28 to 34 bytes of memory) compared to lists which is considered as strings or objects (usually 49 bytes or more of memory)\n",
        "\n",
        "#### - Data Manipulation using *Pandas* is useful since it lets you analyze, compare and manipulate datasets easily using different methods from the *Pandas* library. Also, another usefool tool such as *Matplotlib* and *Seaborn* for data visualizations to further analyze the data using plots like, bar graphs, density plots and scatter plots."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2118fa6-c8e9-4c16-9287-22413eab3b13",
      "metadata": {},
      "source": [
        "## Conclusions\n",
        "\n",
        "#### Today, *NumPy* library was used for array manipulation in Python. 1D and 2D arrays with variable values were created using ***np.array()*** method. Also, basic matrix addition and multiplication were also done using operations such as + and * for both arrays *a* and *b*. Furthermore, the broadcasting feature was applied wherein the size of array *a*, which is a different size compared to array *b*, was manipulated to the same size using manual expansion. \n",
        "\n",
        "#### *Pandas* library was also used for manipulating data in both pokemon and kaggle datasets. In the pokemon datasets, the csv file was loaded using ***read_csv()*** method and filter rows based on certain conditions. Also, columns and values were also dropped to change the dataset into a much more meaningful dataset. Then, summary statistics where also computed using the ***describe()*** method.\n",
        "\n",
        "#### Exploratory Data Analysis was also done using *Pandas*, *Matplotlib* and *Seaborn* libraries for data analysis and visualizations. By displaying numerical and categorical features, the titanic dataset from Kaggle was observed and investigated. The correlation matrix was also computed in order to analyze potential target leakage in the dataset. Moreover, visualizations such as the heat map index, was also used to provide insights of the dataset."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
